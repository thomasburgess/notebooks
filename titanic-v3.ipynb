{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73b643e26a4255de2f20d5c486da3fab1853b105"},"cell_type":"code","source":"# Create full data set\nfull = pd.concat([train.drop('Survived', axis=1), test], axis=0)\nfull.drop('PassengerId', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff5acf685e4638f68b32fcba4522cbd91410b8da"},"cell_type":"code","source":"# We have some null entries\nfull.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a622c10c7e4cabbec619ffbca2e81637a4fe601"},"cell_type":"code","source":"# We impute Embarked and Fare with the mode and mean\nfull['Embarked'].fillna('S', inplace = True)\nfull['Fare'].fillna(full['Fare'].mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49e49dae2482ea72e3e6e949aa56f1e7d91f496c"},"cell_type":"code","source":"# Number of nulls correlates to survivial\n# Instead of imputing we can use this\ndef null_count(df):\n    return df[[\"Cabin\", \"Age\"]].apply(lambda x: x.isnull().astype(int)).sum(axis=1)\ntrain[\"nnull\"] = null_count(train)\nprint(train.groupby(\"nnull\")[[\"Survived\"]].mean())\nfull[\"nnull\"] = null_count(full) # Apply to full dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"926b01cda03ca00a713748e1d14319cdabe0edf2"},"cell_type":"code","source":"# Cabin type (first letter in cabin) also correlates to survival\ndef cabin_type(df):\n    cab = df['Cabin'].astype(str).str[0] # this captures the letter\n    return cab.map(\n        {k: i for i, k in enumerate(cab.unique())})\ntrain[\"Cabin_type\"] = cabin_type(train)\n# this transforms the letters into numbers\nprint(train.groupby(\"Cabin_type\")[[\"Survived\"]].mean())\nfull[\"Cabin_type\"] = cabin_type(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91c935c9d48eae894a9fd747374be17b6c71d9e8"},"cell_type":"code","source":"# We can drop no longer used columns\nfull.drop([\"Cabin\", \"Age\"], inplace=True, axis=1) # Drop replaced column\n# Now there are no more null\nfull.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f0bc75e04ac6aeedbac721b5bb63cb8774a77a5"},"cell_type":"code","source":"# Titles are correlated to survival, but there are many types so we collapse titles to fewer categories\ndef extract_titles(df):\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Officer\",\n        \"Col\":         \"Officer\",\n        \"Major\":       \"Officer\",\n        \"Dr\":          \"Officer\",\n        \"Rev\":         \"Officer\",\n        \"Jonkheer\":    \"Royalty\",\n        \"Don\":         \"Royalty\",\n        \"Sir\" :        \"Royalty\",\n        \"Countess\":    \"Royalty\",\n        \"Dona\":        \"Royalty\",\n        \"Lady\" :       \"Royalty\"\n    }\n    return df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False).map(titles)\ntrain[\"title\"] = extract_titles(train)\n# this transforms the letters into numbers\nprint(train.groupby(\"title\")[[\"Survived\"]].mean())\nfull[\"title\"] = extract_titles(full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d49e5b72632bdbfda33b9ebe2fa0af75073252da"},"cell_type":"code","source":"# Make a famliy size from parch and sibsp\nfull[\"Family_size\"] = full[[\"Parch\", \"SibSp\"]].sum(axis=1)\nfull.drop([\"Parch\", \"SibSp\", 'Name', 'Ticket'], inplace=True, axis=1) # Drop useless columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"792effa5176fb9125ccfa2f581f994b886f9ece6"},"cell_type":"code","source":"dummies = pd.get_dummies(full, columns = ['Sex', \"title\", 'nnull', 'Cabin_type', 'Embarked'])\ndisplay(dummies.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e0f3e50cabe7719ec3df1a2524bf77927fe3f8a"},"cell_type":"code","source":"X = dummies[:len(train)]\nnew_X = dummies[len(train):]\ny = train.Survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"024bfc76a2306ab4c2afc3d028f4e809c0ad352e"},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\ndef select_features(X, y):#\n    xgb = XGBClassifier(n_estimators=40)   \n    rfecv=RFECV(xgb, cv=20)\n    rfecv.fit(X, y)\n    best_columns = list(X.columns[rfecv.support_])\n    print(\"Best Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(best_columns))\n    return best_columns\ncols = select_features(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acd208f6c8a08b80a77c908274e5bde0d25f680a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X[cols], y, test_size = .3, random_state = 1, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"716e8ae2d5172343ffc1e06725b224bad4e3c5e2"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\ngbm_param_grid = {\n    'n_estimators': [5,10,15,20,25,30,40,45],\n    'max_depth': range(6, 10),\n    'learning_rate': [.4, .45, .5, .55, .6],\n    'colsample_bytree': [.6, .7, .8, .9, 1]\n}\n\n# Instantiate the regressor: gbm\ngbm = XGBClassifier()\n\n# Perform random search: grid_mse\nxgb_grid = GridSearchCV(\n    gbm, gbm_param_grid, \n    cv = 8, verbose=1)\n\n# Fit randomized_mse to the data\nxgb_grid.fit(X, y)\n# Print the best parameters and lowest RMSE\nprint(\"Best parameters found: \", xgb_grid.best_params_)\nprint(\"Best accuracy found: \", xgb_grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c014ba2fba38722d47aeb9545ecd3f47f73aebf"},"cell_type":"code","source":"xgb_pred = xgb_grid.predict(new_X)\nsubmission = pd.concat([test.PassengerId, pd.DataFrame(xgb_pred)], axis = 'columns')\nsubmission.columns = [\"PassengerId\", \"Survived\"]\nsubmission.to_csv('titanic_submission.csv', header = True, index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}